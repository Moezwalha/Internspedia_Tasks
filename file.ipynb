{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"file.ipynb","provenance":[],"authorship_tag":"ABX9TyNBKppduZGiiBtgBPZmAY11"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import urllib.request, json , time, os, difflib, itertools\n","import pandas as pd\n","from multiprocessing.dummy import Pool\n","from datetime import datetime"],"metadata":{"id":"GrAVyZmoVSoo","executionInfo":{"status":"ok","timestamp":1657980422768,"user_tz":-60,"elapsed":725,"user":{"displayName":"MOEZ WALHA","userId":"10988629885770028512"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["try:\n","    import httplib\n","except:\n","    import http.client as httplib\n","\n","def check_internet():\n","    conn = httplib.HTTPConnection(\"www.google.com\", timeout=5)\n","    try:\n","        conn.request(\"HEAD\", \"/\")\n","        conn.close()\n","        # print(\"True\")\n","        return True\n","    except:\n","        conn.close()\n","        # print(\"False\")\n","        return False"],"metadata":{"id":"E7hOjtfbWDGR","executionInfo":{"status":"ok","timestamp":1657980613263,"user_tz":-60,"elapsed":320,"user":{"displayName":"MOEZ WALHA","userId":"10988629885770028512"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"TO-kf7p0I0-E","executionInfo":{"status":"ok","timestamp":1657980402835,"user_tz":-60,"elapsed":18,"user":{"displayName":"MOEZ WALHA","userId":"10988629885770028512"}}},"outputs":[],"source":["def get_historic_price(query_url,json_path,csv_path):\n","    \n","    while not check_internet():\n","        print(\"Could not connect, trying again in 5 seconds...\")\n","        time.sleep(5)\n","    \n","    stock_id=query_url.split(\"&period\")[0].split(\"symbol=\")[1]\n","    \n","    if os.path.exists(csv_path+stock_id+'.csv') and os.stat(csv_path+stock_id+'.csv').st_size != 0:\n","        print(\"<<<  Historical data of \"+stock_id+\" already exists, Updating data...\")\n","\n","    try:\n","        with urllib.request.urlopen(query_url) as url:\n","            parsed = json.loads(url.read().decode())\n","    except:\n","        print(\"|||  Historical data of \"+stock_id+\" doesn't exist\")\n","        return\n","    \n","    else:\n","        if os.path.exists(json_path+stock_id+'.json'):\n","            os.remove(json_path+stock_id+'.json')\n","        with open(json_path+stock_id+'.json', 'w') as outfile:\n","            json.dump(parsed, outfile, indent=4)\n","\n","        try:\n","            Date=[]\n","            for i in parsed['chart']['result'][0]['timestamp']:\n","                Date.append(datetime.utcfromtimestamp(int(i)).strftime('%d-%m-%Y'))\n","\n","            Low=parsed['chart']['result'][0]['indicators']['quote'][0]['low']\n","            Open=parsed['chart']['result'][0]['indicators']['quote'][0]['open']\n","            Volume=parsed['chart']['result'][0]['indicators']['quote'][0]['volume']\n","            High=parsed['chart']['result'][0]['indicators']['quote'][0]['high']\n","            Close=parsed['chart']['result'][0]['indicators']['quote'][0]['close']\n","            Adjusted_Close=parsed['chart']['result'][0]['indicators']['adjclose'][0]['adjclose']\n","\n","            df=pd.DataFrame(list(zip(Date,Low,Open,Volume,High,Close,Adjusted_Close)),columns =['Date','Low','Open','Volume','High','Close','Adjusted Close'])\n","\n","            if os.path.exists(csv_path+stock_id+'.csv'):\n","                os.remove(csv_path+stock_id+'.csv')\n","            df.to_csv(csv_path+stock_id+'.csv', sep=',', index=None)\n","            print(\">>>  Historical data of \"+stock_id+\" saved\")\n","            return\n","        except:\n","            print(\">>>  Historical data of \"+stock_id+\" exists but has no trading data\")"]},{"cell_type":"code","source":["json_path = os.getcwd()+os.sep+\"..\"+os.sep+\"historic_data\"+os.sep+\"json\"+os.sep\n","csv_path = os.getcwd()+os.sep+\"..\"+os.sep+\"historic_data\"+os.sep+\"csv\"+os.sep"],"metadata":{"id":"8CTGW9LoVZY7","executionInfo":{"status":"ok","timestamp":1657980473315,"user_tz":-60,"elapsed":332,"user":{"displayName":"MOEZ WALHA","userId":"10988629885770028512"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["if not os.path.isdir(json_path):\n","    os.makedirs(json_path)\n","if not os.path.isdir(csv_path):\n","    os.makedirs(csv_path)"],"metadata":{"id":"13rVBuKFVkzf","executionInfo":{"status":"ok","timestamp":1657980999919,"user_tz":-60,"elapsed":330,"user":{"displayName":"MOEZ WALHA","userId":"10988629885770028512"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["query_url = \"https://query1.finance.yahoo.com/v8/finance/chart/NFLX?symbol=NFLX&period1=1437004800&period2=9999999999&interval=1d&includePrePost=true&events=div%2Csplit\""],"metadata":{"id":"Wv2yleceVoSd","executionInfo":{"status":"ok","timestamp":1657981002016,"user_tz":-60,"elapsed":10,"user":{"displayName":"MOEZ WALHA","userId":"10988629885770028512"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["get_historic_price(query_url,json_path,csv_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WuIQgG4aV8tm","executionInfo":{"status":"ok","timestamp":1657981003789,"user_tz":-60,"elapsed":321,"user":{"displayName":"MOEZ WALHA","userId":"10988629885770028512"}},"outputId":"b4702826-c683-45a8-9cbd-662b0f4877e9"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":[">>>  Historical data of NFLX saved\n"]}]}]}